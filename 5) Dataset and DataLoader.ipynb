{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import math\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xy = np.loadtxt('wine.csv',delimiter=\",\", dtype=np.float32, skiprows=1)\n",
    "xy[:,0].shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Totensor:\n",
    "    #numpy to tensor\n",
    "    def __call__(self, sample):\n",
    "        inputs, labels = sample\n",
    "        return torch.from_numpy(inputs), torch.from_numpy(labels)\n",
    "\n",
    "class MulTransform:\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "\n",
    "    def __call__(self, sample):\n",
    "         inputs, target = sample\n",
    "         input *= self.factor\n",
    "         return inputs, target\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### from numpy to tensor using transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 1.2968e+00, -3.1999e-01,  5.4555e-01,  4.9695e-01, -5.9301e-01,\n",
       "          1.2029e+00, -4.1456e-01,  8.5052e-01, -7.1279e-01, -1.5776e+00,\n",
       "          1.2208e+00,  2.0986e-01, -4.7381e-01, -4.5965e-01,  7.1617e-01,\n",
       "          5.3627e-01, -1.0432e+00,  3.0744e-01, -6.2234e-01,  7.7788e-01,\n",
       "          7.2111e-01, -3.7497e-01,  4.4063e-01,  3.5764e-01,  7.2604e-01,\n",
       "          4.6235e-01, -2.5921e-01, -7.8426e-01,  1.4248e+00,  2.9538e-02,\n",
       "         -5.4945e-01,  1.8394e+00,  2.1357e-01, -9.1789e-01, -8.0162e-01,\n",
       "          1.0039e-03,  3.4410e-03,  8.7306e-01,  2.0970e-01,  1.1660e+00,\n",
       "         -1.1301e+00, -3.8363e-01,  1.9884e+00,  1.9703e+00,  2.4899e+00,\n",
       "         -1.3758e+00,  8.1196e-01,  1.1710e+00, -1.1298e+00, -2.7490e+00,\n",
       "          8.0920e-01,  1.7800e+00, -4.7488e-01,  1.5887e+00, -5.0454e-01,\n",
       "         -3.2926e-01,  1.4655e+00, -1.9810e+00, -5.3382e-01,  9.6849e-01,\n",
       "         -4.6878e-01,  2.4608e-01, -1.2265e+00,  3.9350e-01,  2.6071e-01,\n",
       "          1.2103e+00, -8.5871e-02,  8.4127e-01,  5.3832e-01,  2.3878e-01,\n",
       "         -8.2002e-01, -1.2213e+00,  1.0344e+00,  2.6533e-02,  1.4185e+00,\n",
       "         -1.9250e-01, -1.3174e-01, -1.2836e-01,  1.3473e+00, -1.0166e+00,\n",
       "         -9.7915e-01, -3.8960e-01, -3.5419e-01, -4.2275e-01, -1.5508e+00,\n",
       "          1.0105e+00,  8.9216e-01,  6.8453e-01, -2.3440e-02, -3.6743e-01,\n",
       "         -9.2420e-02, -6.6459e-01,  1.3703e+00, -1.3387e+00, -2.3845e-01,\n",
       "         -6.2498e-01,  1.2195e+00,  7.3748e-01, -1.9310e-01,  3.2503e-01],\n",
       "        dtype=torch.float64),\n",
       " tensor([101.2221, 100.6588,  99.1973,  98.7506, 100.2804,  99.4887, 102.1849,\n",
       "          99.0400, 100.9274,  99.5947, 100.4359,  98.2521, 100.4513,  99.0439,\n",
       "          99.1600, 100.6510, 100.8500,  99.0500,  98.8805,  99.9996, 100.2091,\n",
       "         100.1278, 100.5508, 101.4892, 100.8142,  99.3264,  99.7608,  99.0761,\n",
       "         100.1270,  98.4511, 100.5283, 100.4622,  96.6589, 100.1332, 101.0393,\n",
       "          99.7552, 101.1172, 101.4422,  99.6685, 100.9502, 100.3883,  99.7064,\n",
       "         100.0114,  99.3065, 100.6978,  98.4822,  99.8366, 100.6441, 102.0586,\n",
       "          98.8888,  98.8294, 100.8428, 100.7405, 102.1920, 100.1272, 100.5367,\n",
       "         100.8009,  98.8246, 100.0628,  99.8279, 100.6939,  99.1113, 100.9747,\n",
       "          97.8642, 100.3792, 100.4286,  99.4593,  99.6528,  98.8239,  99.4363,\n",
       "         100.9949,  99.2649, 100.4739, 100.4542,  99.9208, 101.0784, 101.0522,\n",
       "          99.5685,  99.7553,  98.5519,  99.9389,  99.3273,  99.1872,  99.8451,\n",
       "         100.8354,  99.3141, 100.3881,  99.2945, 100.1507, 101.1207, 100.6075,\n",
       "          98.7003, 100.0688, 100.5583,  99.7080, 100.7108,  99.4051, 100.1710,\n",
       "         100.5604, 100.4427], dtype=torch.float64))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat = (np.random.normal(size=100),np.random.normal(100,size=100))\n",
    "#how to use callable object\n",
    "t = Totensor()\n",
    "t(dat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "epoch - 1 forward and backward pass of ALL training samples\n",
    "batch_size - number of training sample in one forward and backward pass\n",
    "number of iterations - number of passes, each pass using batch_size number of sample\n",
    "\n",
    "e.g. 100 samples, batch_size=20 --> 100/20 = 5 iterations for 1 epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WineDataset(Dataset):\n",
    "\n",
    "    def __init__(self, transform=None):\n",
    "        #data loading\n",
    "        xy = np.loadtxt('wine.csv', delimiter=\",\", dtype=np.float32, skiprows=1)\n",
    "        self.x = xy[:,1:]\n",
    "        self.y = xy[:,[0]] #convert to 2d-array\n",
    "\n",
    "        self.transform = transform\n",
    "\n",
    "        self.n_samples = xy.shape[0]\n",
    "    def __getitem__(self, index):\n",
    "        #dataset[0]\n",
    "        sample = (self.x[index], self.y[index])\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return  sample\n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "\n",
    "    def n_features(self):\n",
    "        return self.x.shape[1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "composed = torchvision.transforms.Compose([Totensor(), MulTransform(4)])\n",
    "dataset = WineDataset(transform=composed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'input' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m dataloader \u001b[38;5;241m=\u001b[39m DataLoader(dataset\u001b[38;5;241m=\u001b[39mdataset, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, drop_last\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      5\u001b[0m dataiter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(dataloader)\n\u001b[0;32m----> 6\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataiter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m feature \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      9\u001b[0m label \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/paper/lib/python3.11/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/paper/lib/python3.11/site-packages/torch/utils/data/dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/anaconda3/envs/paper/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/anaconda3/envs/paper/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[9], line 17\u001b[0m, in \u001b[0;36mWineDataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     14\u001b[0m sample \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx[index], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my[index])\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform:\n\u001b[0;32m---> 17\u001b[0m     sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m  sample\n",
      "File \u001b[0;32m~/anaconda3/envs/paper/lib/python3.11/site-packages/torchvision/transforms/transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[0;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "Cell \u001b[0;32mIn[7], line 13\u001b[0m, in \u001b[0;36mMulTransform.__call__\u001b[0;34m(self, sample)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, sample):\n\u001b[1;32m     12\u001b[0m      inputs, target \u001b[38;5;241m=\u001b[39m sample\n\u001b[0;32m---> 13\u001b[0m      \u001b[38;5;28;43minput\u001b[39;49m \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfactor\n\u001b[1;32m     14\u001b[0m      \u001b[38;5;28;01mreturn\u001b[39;00m inputs, target\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: cannot access local variable 'input' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "batch_size = 4\n",
    "\n",
    "dataloader = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "dataiter = iter(dataloader)\n",
    "data = next(dataiter)\n",
    "\n",
    "feature = data[0]\n",
    "label = data[1]\n",
    "\n",
    "print(feature.shape) #batch size, feature num\n",
    "print(label.shape) #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178 45\n",
      "epoch 1, step: 0/45\n",
      "epoch 1, step: 1/45\n",
      "epoch 1, step: 2/45\n",
      "epoch 1, step: 3/45\n",
      "epoch 1, step: 4/45\n",
      "epoch 1, step: 5/45\n",
      "epoch 1, step: 6/45\n",
      "epoch 1, step: 7/45\n",
      "epoch 1, step: 8/45\n",
      "epoch 1, step: 9/45\n",
      "epoch 1, step: 10/45\n",
      "epoch 1, step: 11/45\n",
      "epoch 1, step: 12/45\n",
      "epoch 1, step: 13/45\n",
      "epoch 1, step: 14/45\n",
      "epoch 1, step: 15/45\n",
      "epoch 1, step: 16/45\n",
      "epoch 1, step: 17/45\n",
      "epoch 1, step: 18/45\n",
      "epoch 1, step: 19/45\n",
      "epoch 1, step: 20/45\n",
      "epoch 1, step: 21/45\n",
      "epoch 1, step: 22/45\n",
      "epoch 1, step: 23/45\n",
      "epoch 1, step: 24/45\n",
      "epoch 1, step: 25/45\n",
      "epoch 1, step: 26/45\n",
      "epoch 1, step: 27/45\n",
      "epoch 1, step: 28/45\n",
      "epoch 1, step: 29/45\n",
      "epoch 1, step: 30/45\n",
      "epoch 1, step: 31/45\n",
      "epoch 1, step: 32/45\n",
      "epoch 1, step: 33/45\n",
      "epoch 1, step: 34/45\n",
      "epoch 1, step: 35/45\n",
      "epoch 1, step: 36/45\n",
      "epoch 1, step: 37/45\n",
      "epoch 1, step: 38/45\n",
      "epoch 1, step: 39/45\n",
      "epoch 1, step: 40/45\n",
      "epoch 1, step: 41/45\n",
      "epoch 1, step: 42/45\n",
      "epoch 1, step: 43/45\n",
      "epoch 2, step: 0/45\n",
      "epoch 2, step: 1/45\n",
      "epoch 2, step: 2/45\n",
      "epoch 2, step: 3/45\n",
      "epoch 2, step: 4/45\n",
      "epoch 2, step: 5/45\n",
      "epoch 2, step: 6/45\n",
      "epoch 2, step: 7/45\n",
      "epoch 2, step: 8/45\n",
      "epoch 2, step: 9/45\n",
      "epoch 2, step: 10/45\n",
      "epoch 2, step: 11/45\n",
      "epoch 2, step: 12/45\n",
      "epoch 2, step: 13/45\n",
      "epoch 2, step: 14/45\n",
      "epoch 2, step: 15/45\n",
      "epoch 2, step: 16/45\n",
      "epoch 2, step: 17/45\n",
      "epoch 2, step: 18/45\n",
      "epoch 2, step: 19/45\n",
      "epoch 2, step: 20/45\n",
      "epoch 2, step: 21/45\n",
      "epoch 2, step: 22/45\n",
      "epoch 2, step: 23/45\n",
      "epoch 2, step: 24/45\n",
      "epoch 2, step: 25/45\n",
      "epoch 2, step: 26/45\n",
      "epoch 2, step: 27/45\n",
      "epoch 2, step: 28/45\n",
      "epoch 2, step: 29/45\n",
      "epoch 2, step: 30/45\n",
      "epoch 2, step: 31/45\n",
      "epoch 2, step: 32/45\n",
      "epoch 2, step: 33/45\n",
      "epoch 2, step: 34/45\n",
      "epoch 2, step: 35/45\n",
      "epoch 2, step: 36/45\n",
      "epoch 2, step: 37/45\n",
      "epoch 2, step: 38/45\n",
      "epoch 2, step: 39/45\n",
      "epoch 2, step: 40/45\n",
      "epoch 2, step: 41/45\n",
      "epoch 2, step: 42/45\n",
      "epoch 2, step: 43/45\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 2\n",
    "lr = 0.01\n",
    "\n",
    "total_samples = len(dataset)\n",
    "n_iterations = math.ceil(total_samples / batch_size)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(total_samples, n_iterations)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (input,label) in enumerate(dataloader):\n",
    "\n",
    "        print(\"epoch {}, step: {}/{}\".format(epoch+1, i, n_iterations))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
